"""
Data Node - ë°ì´í„° ë¶„ì„ ë…¸ë“œ

LangGraph ê¸°ë°˜ì˜ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ë…¸ë“œì…ë‹ˆë‹¤.
"""

from typing import Dict, Any
import logging
import os
from datetime import datetime
from models import State, Task, UserFeedback
from langchain_openai import ChatOpenAI
from langchain.tools import Tool
from langchain_core.prompts import PromptTemplate


async def data_node(state: State) -> State:
    """
    ë°ì´í„° ë¶„ì„ ë…¸ë“œ
    
    Args:
        state (State): í˜„ì¬ ìƒíƒœ
        
    Returns:
        State: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
    """
    print("\n\n============= DATA NODE ==============\n")
    
    logger = logging.getLogger("node.data")
    logger.info("Data node processing started")
    
    try:
        # í˜„ì¬ ì‘ì—… í™•ì¸
        current_task = state.get("current_task")
        if not current_task or current_task.agent != "data_agent":
            logger.warning("Data node called without proper task assignment")
            return state
        
        user_id = state.get("user_id", 1)
        user_request = state.get("user_request", "")
        
        # ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
        data_analysis = perform_data_analysis(user_id, user_request, state)
        
        # í”¼ë“œë°± ë°ì´í„° ì—…ë°ì´íŠ¸
        feedback_data = state.get("feedback_data", [])
        if data_analysis.get("new_feedback"):
            new_feedback = UserFeedback(
                feedback_id=data_analysis["new_feedback"]["feedback_id"],
                user_id=user_id,
                text=data_analysis["new_feedback"]["text"],
                rating=data_analysis["new_feedback"]["rating"],
                category=data_analysis["new_feedback"]["category"],
                sentiment=data_analysis["new_feedback"]["sentiment"]
            )
            feedback_data.append(new_feedback)
        
        # ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
        messages = state.get("messages", [])
        data_message = {
            "role": "assistant",
            "content": f"[Data Agent] ë°ì´í„° ë¶„ì„ ì™„ë£Œ: {data_analysis['insights_count']}ê°œ ì¸ì‚¬ì´íŠ¸ ìƒì„±",
            "timestamp": datetime.now().isoformat(),
            "agent": "data_agent"
        }
        messages.append(data_message)
        
        # ì‘ì—… ì™„ë£Œ ì²˜ë¦¬
        task_history = state.get("task_history", [])
        if task_history:
            task_history[-1].done = True
            task_history[-1].done_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # AI ì¶”ì²œ ìƒì„±
        ai_recommendation = await generate_data_recommendation(data_analysis, state)
        
        # AI ì‘ë‹µ ìƒì„±
        ai_response = f"ë°ì´í„° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
        ai_response += f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {data_analysis.get('analysis_type', 'ì¼ë°˜ ë¶„ì„')}\n"
        ai_response += f"ğŸ“ˆ ìƒì‚°ì„± ì ìˆ˜: {data_analysis.get('productivity_score', 0)}/100\n"
        ai_response += f"ğŸ¯ ê°œì„  ì˜ì—­: {len(data_analysis.get('improvement_areas', []))}ê°œ\n"
        ai_response += f"ğŸ’¡ ì¸ì‚¬ì´íŠ¸: {len(data_analysis.get('insights', []))}ê°œ\n\n"
        ai_response += ai_recommendation
        
        logger.info("Data node processing completed successfully")
        
        return {
            **state,
            "messages": messages,
            "feedback_data": feedback_data,
            "task_history": task_history,
            "ai_recommendation": ai_recommendation,
            "ai_response": ai_response,
            "system_status": "data_analysis_completed"
        }
        
    except Exception as e:
        logger.error(f"Error in data node: {str(e)}")
        error_messages = state.get("error_messages", [])
        error_messages.append(f"Data node error: {str(e)}")
        
        return {
            **state,
            "error_messages": error_messages,
            "system_status": "error"
        }


def perform_data_analysis(user_id: int, user_request: str, state: State) -> Dict[str, Any]:
    """
    ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        user_id (int): ì‚¬ìš©ì ID
        user_request (str): ì‚¬ìš©ì ìš”ì²­
        state (State): í˜„ì¬ ìƒíƒœ
        
    Returns:
        Dict[str, Any]: ë°ì´í„° ë¶„ì„ ê²°ê³¼
    """
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  íŒ¨í„´ì„ ì°¾ìŒ
    # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜
    
    analysis = {
        "user_behavior_patterns": {
            "most_active_hours": [9, 10, 14, 15],
            "preferred_work_style": "focused_blocks",
            "break_patterns": "regular_breaks",
            "productivity_peaks": ["morning", "afternoon"]
        },
        "productivity_metrics": {
            "average_task_completion_rate": 0.85,
            "time_estimation_accuracy": 0.78,
            "focus_time_percentage": 0.72,
            "distraction_frequency": 0.15
        },
        "insights": [
            "ì˜¤ì „ 9-11ì‹œì— ê°€ì¥ ë†’ì€ ìƒì‚°ì„±ì„ ë³´ì…ë‹ˆë‹¤",
            "ì ì‹¬ ì‹œê°„ í›„ 1-2ì‹œê°„ì€ ì—ë„ˆì§€ê°€ ë‚®ì•„ì§‘ë‹ˆë‹¤",
            "ê¹Šì€ ì‘ì—… ì„¸ì…˜ì„ ìì£¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤"
        ],
        "trends": {
            "productivity_trend": "improving",
            "workload_trend": "stable",
            "satisfaction_trend": "improving"
        },
        "insights_count": 3
    }
    
    # ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ ë§ì¶¤ ë¶„ì„
    if "íŒ¨í„´" in user_request or "pattern" in user_request.lower():
        analysis["insights"].append("ê·œì¹™ì ì¸ ì‘ì—… íŒ¨í„´ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤")
        analysis["insights_count"] += 1
    
    if "ì„±ê³¼" in user_request or "performance" in user_request.lower():
        analysis["insights"].append("ì „ë°˜ì ì¸ ì„±ê³¼ê°€ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤")
        analysis["insights_count"] += 1
    
    # ìƒˆë¡œìš´ í”¼ë“œë°±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
    if "í”¼ë“œë°±" in user_request or "feedback" in user_request.lower():
        analysis["new_feedback"] = {
            "feedback_id": f"feedback_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "text": "ì‚¬ìš©ì í”¼ë“œë°±ì´ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            "rating": 4.2,
            "category": "general",
            "sentiment": "positive"
        }
    
    return analysis


async def generate_data_recommendation(data_analysis: Dict[str, Any], state: State) -> str:
    """
    ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ AI ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        data_analysis (Dict[str, Any]): ë°ì´í„° ë¶„ì„ ê²°ê³¼
        state (State): í˜„ì¬ ìƒíƒœ
        
    Returns:
        str: AI ì¶”ì²œ ë©”ì‹œì§€
    """
    try:
        from langchain_openai import ChatOpenAI
        import os
        
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=os.getenv("OPENAI_API_KEY"),
            temperature=0.7,
            streaming=True  # ìŠ¤íŠ¸ë¦¼ ì¶œë ¥ í™œì„±í™”
        )
        
        prompt = f"""
        ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ìƒì‚°ì„± ê°œì„  ë°©ì•ˆì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        ì‚¬ìš©ì í–‰ë™ íŒ¨í„´:
        {data_analysis['user_behavior_patterns']}
        
        ìƒì‚°ì„± ì§€í‘œ:
        {data_analysis['productivity_metrics']}
        
        ì¸ì‚¬ì´íŠ¸:
        {data_analysis['insights']}
        
        íŠ¸ë Œë“œ:
        {data_analysis['trends']}
        
        ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒì‚°ì„± ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        # ìŠ¤íŠ¸ë¦¼ ì¶œë ¥ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        full_response = ""
        print("AI ì‘ë‹µ: ", end="", flush=True)
        
        import time
        async for chunk in llm.astream(prompt):
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end="", flush=True)
                full_response += chunk.content
                time.sleep(0.02)  # íƒ€ì´í•‘ íš¨ê³¼
        
        print()  # ì¤„ë°”ê¿ˆ
        return full_response
    except Exception as e:
        # í´ë°±: ê¸°ë³¸ ì¶”ì²œ
        productivity_trend = data_analysis["trends"]["productivity_trend"]
        insights_count = data_analysis["insights_count"]
        
        if productivity_trend == "improving":
            recommendation = "ìƒì‚°ì„±ì´ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ íŒ¨í„´ì„ ìœ ì§€í•˜ì„¸ìš”."
        elif productivity_trend == "stable":
            recommendation = "ìƒì‚°ì„±ì´ ì•ˆì •ì ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë„ì „ì„ ì‹œë„í•´ë³´ì„¸ìš”."
        else:
            recommendation = "ìƒì‚°ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì‘ì—… ë°©ì‹ì„ ì¬ê²€í† í•´ë³´ì„¸ìš”."
        
        recommendation += f" {insights_count}ê°œì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤."
        
        return f"{recommendation} (API ì˜¤ë¥˜: {str(e)})"
